{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a81642c1-6977-4637-b2d5-802f4a3255c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c4eb678-2d02-41a0-981d-c6ab8204a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = \"AIzaSyBUVvgM4XgmGOXeHu-FKsJqehdCrrXW_pY\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf7655c5-4bde-413d-a877-5c443b5d316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf6307fe-cb6c-4bb0-9068-ba226ef457c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ArticleSummaryOutput(BaseModel):\n",
    "    \n",
    "    article_url: str = Field(..., description=\"The Substack article URL\")\n",
    "    summary: str = Field(..., description=\"Short, meaningful summary of the article\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f9304d1-d259-4648-9d9d-a4442cc19e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "article_url = \"https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9e6989f-c334-496c-b51a-d4dfcfb8519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article(article_url: str, client: genai.Client) -> ArticleSummaryOutput:\n",
    "    prompt = f\"\"\"\n",
    "    Summarize the article at this URL in 2â€“3 concise sentences.\n",
    "    Return a JSON with:\n",
    "    - article_url: repeat the URL\n",
    "    - summary: the main idea in 2â€“3 sentences\n",
    "\n",
    "    URL: {article_url}\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt],\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_json_schema\": ArticleSummaryOutput.model_json_schema(),\n",
    "        },\n",
    "    )\n",
    "    return ArticleSummaryOutput.model_validate_json(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d86dbfdc-b5b1-407c-80e2-18bccef79709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleSummaryOutput(article_url='https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated', summary=\"Gary Marcus discusses how OpenAI's O3 and Grok-4, despite not being explicitly designed with symbolic AI in mind, exhibit improved reasoning abilities that inadvertently validate the importance of integrating symbolic approaches with neural networks. He argues that their unexpected success suggests a convergence towards hybrid AI systems that combine the strengths of both connectionist and symbolic methods for more robust and reliable AI.\")"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_result = summarize_article(article_url, client)\n",
    "summary_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "df75fc50-73a1-4425-8ace-1f0239312bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ArticleQuotedInfoOutput(BaseModel):\n",
    "    article_url: str = Field(..., description=\"URL of the article\")\n",
    "    \n",
    "    quoted_information: list[str] = Field(..., description=\"List of quotes or quoted phrases found in the article\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cde223f0-8d92-427c-9e7d-fa2db8166f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ArticleQuotedInfoOutput(BaseModel):\n",
    "    article_url: str = Field(..., description=\"URL of the article\")\n",
    "    \n",
    "    quoted_information: list[str] = Field(..., description=\"List of quotes or quoted phrases found in the article\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e7118953-b639-4d51-bdd0-935f95e64263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_article_with_quotes(article_url: str, client: genai.Client) -> ArticleQuotedInfoOutput:\n",
    "    prompt = f\"\"\"\n",
    "    Read the article at the URL below and return structured JSON with:\n",
    "    - \"article_url\": repeat the input URL\n",
    "    \n",
    "    - \"quoted_information\": a list of all phrases or sentences that appear within quotes in the article (e.g. â€œlike thisâ€ or 'like that')\n",
    "\n",
    "    Only respond with valid JSON in the correct schema.\n",
    "\n",
    "    URL: {article_url}\n",
    "    \"\"\"\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt],\n",
    "        config={\n",
    "            \"response_mime_type\": \"application/json\",\n",
    "            \"response_json_schema\": ArticleQuotedInfoOutput.model_json_schema(),\n",
    "        },\n",
    "    )\n",
    "    return ArticleQuotedInfoOutput.model_validate_json(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "87f6c9fc-c0c9-4bb7-9294-118638236f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ArticleQuotedInfoOutput(article_url='https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated', quoted_information=['â€œthe ability to retain facts over long contexts,â€', 'â€œneedle in a haystackâ€', 'â€œlong context recallâ€', 'â€œWe believe that this demonstrates that we can significantly improve long context recall without sacrificing quality in other areas.â€', 'â€œnear-perfect recallâ€', 'â€œThese results suggest that Grok-1.5 exhibits near-perfect recall up to 128K tokens in our evaluations.â€', 'â€œnear-perfect recallâ€', 'â€œcanâ€™t handle the long tailâ€', 'â€œIn other words, when models are evaluated for their ability to retrieve relevant information from longer contexts, performance drops off significantly. This is what we mean by canâ€™t handle the long tail.â€', 'â€œthe AI community (or at least a vocal subset thereof) has been consistently overconfidentâ€', 'â€œdelusional levelsâ€', 'â€œan uncanny ability to retrieve information from across a 128,000 token context window,â€', 'â€œthe AI community (or at least a vocal subset thereof) has been consistently overconfidentâ€', 'â€œdelusional levelsâ€', 'â€œhallucinating lessâ€', 'â€œa big dealâ€', 'â€œlong context is all you needâ€', 'â€œSystem 1â€', 'â€œSystem 2â€', 'â€œSystem 1â€', 'â€œSystem 2â€', 'â€œSystem 1â€', 'â€œSystem 2â€', 'â€œSystem 1â€', 'â€œSystem 2â€'])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quoted_result = summarize_article_with_quotes(article_url, client)\n",
    "\n",
    "quoted_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "af793bd1-5494-46ee-95a4-b9e02113275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quoted_info = quoted_result.quoted_information\n",
    "url = quoted_result.article_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "1e7bd253-295b-46eb-b40a-9aec38531d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ {\n",
      "  \"article_url\": \"https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated\",\n",
      "  \"summary\": \"Gary Marcus discusses how OpenAI's O3 and Grok-1.5, while still flawed, demonstrate a move towards more reliable and less hallucinatory AI models. He argues that their improved performance, particularly in reasoning and coherence, inadvertently supports the need for incorporating more structured approaches and 'deep understanding' into AI development, vindicating his long-held views.\"\n",
      "}\n",
      "\n",
      "ðŸ”¹ â€œthe ability to retain facts over long contexts,â€\n",
      "ðŸ”¹ â€œneedle in a haystackâ€\n",
      "ðŸ”¹ â€œlong context recallâ€\n",
      "\n",
      "Read the full article ðŸ‘‰ https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated\n",
      "#AI #TechNews #LinkedInLearning\n"
     ]
    }
   ],
   "source": [
    "def generate_linkedin_post(summary: str, quoted_information: list[str], article_url: str) -> str:\n",
    "    bullets = \"\\n\".join([f'ðŸ”¹ {quote}' for quote in quoted_information[:3]])\n",
    "    linkedin_post = f\"\"\"\n",
    "ðŸš€ {summary.strip()}\n",
    "\n",
    "{bullets}\n",
    "\n",
    "Read the full article ðŸ‘‰ {article_url}\n",
    "#AI #TechNews #LinkedInLearning\n",
    "\"\"\".strip()\n",
    "    return linkedin_post\n",
    "\n",
    "# Generate post\n",
    "linkedin_post = generate_linkedin_post(summary, quoted_info , article_url)\n",
    "print(linkedin_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5a6b5cc9-5d81-4dfa-a20a-f4d340969da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*Key Highlights from the Article:*\n",
      "ðŸ”¹ â€œthe ability to retain facts over long contexts,â€\n",
      "ðŸ”¹ â€œneedle in a haystackâ€\n",
      "ðŸ”¹ â€œlong context recallâ€\n",
      "ðŸ”¹ â€œWe believe that this demonstrates that we can significantly improve long context recall without sacrificing quality in other areas.â€\n",
      "ðŸ”¹ â€œnear-perfect recallâ€\n"
     ]
    }
   ],
   "source": [
    "def create_whatsapp_post(quoted_information: list[str], article_url: str) -> str:\n",
    "    bullets = \"\\n\".join([f'ðŸ”¹ {quote}' for quote in quoted_information[:5]])\n",
    "    whatsapp_post = f\"\"\"\n",
    "  *Key Highlights from the Article:*\n",
    "{bullets}\n",
    "\n",
    " \n",
    "\"\"\".strip()\n",
    "    return whatsapp_post\n",
    "\n",
    "# Example usage\n",
    "whatsapp_post = create_whatsapp_post(quoted_info, article_url)\n",
    "print(whatsapp_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "36d50612-b4c0-4d02-9f5b-2c57555d3109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ \"â€œthe ability to retain facts over long contexts,â€\"\n",
      "ðŸ’¬ \"â€œneedle in a haystackâ€\"\n",
      "\n",
      "ðŸ”— https://garymarcus.substack.com/p/how-o3-and-grok-4-accidentally-vindicated\n",
      "#AI #News\n"
     ]
    }
   ],
   "source": [
    "def create_twitter_post(quoted_information: list[str], article_url: str) -> str:\n",
    "    tweet_lines = [f'ðŸ’¬ \"{quote}\"' for quote in quoted_information[:2]]  # Max 2 quotes for brevity\n",
    "    quotes_section = \"\\n\".join(tweet_lines)\n",
    "    \n",
    "    hashtags = \"#AI #News\"  \n",
    "    \n",
    "    twitter_post = f\"\"\"\n",
    "{quotes_section}\n",
    "\n",
    "ðŸ”— {article_url}\n",
    "{hashtags}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    \n",
    "    if len(twitter_post) > 280:\n",
    "        # Trim quotes if necessary\n",
    "        trimmed_quotes = [q[:100] + \"...\" if len(q) > 100 else q for q in quoted_information[:2]]\n",
    "        quotes_section = \"\\n\".join([f'ðŸ’¬ \"{quote}\"' for quote in trimmed_quotes])\n",
    "        twitter_post = f\"{quotes_section}\\n\\nðŸ”— {article_url}\\n{hashtags}\"\n",
    "\n",
    "    return twitter_post\n",
    "\n",
    "\n",
    "twitter_post = create_twitter_post(quoted_info, article_url)\n",
    "print(twitter_post)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce132cb-94d3-4062-832f-5acf44726132",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea469ff-0e9d-4183-aab0-75f6331ee913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
